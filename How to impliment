Okay, here's a streamlined guide for using your AI-Powered Resume Screening and Ranking System

AI-Powered Resume Screening and Ranking System

This project provides an AI-powered solution for screening and ranking resumes based on their suitability for a given job description. It leverages machine learning, natural language processing (NLP), and a MySQL database to automate the resume review process.

Technology Stack

Web Framework: Streamlit

Database: MySQL

Data Handling: Pandas

NLP: spaCy

Resume Parsing: python-docx, pdfminer.six

Database ORM: SQLAlchemy

Machine Learning: Scikit-learn (sklearn), Joblib

Setup and Execution

Follow these steps to get the application running on your local machine:

Clone the Repository:

git clone [your repository URL]
cd resume_screening_app_ml


Create a Virtual Environment:

python3 -m venv venv
source venv/bin/activate   # Linux/macOS
# venv\Scripts\activate    # Windows
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

Install Dependencies:

pip install -r requirements.txt
python -m spacy download en_core_web_sm
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

Configure Your MySQL Database:

Ensure you have a MySQL server running.

Create a database named resume_db.

Create a user with appropriate privileges to access the database.

Update the config.py file with your database credentials. Important: Replace the placeholder values for DATABASE_USER, DATABASE_PASSWORD, and DATABASE_HOST with your actual database credentials.

# config.py
DATABASE_USER = "your_db_user"
DATABASE_PASSWORD = "your_db_password"
DATABASE_HOST = "localhost"  # Or your database host
DATABASE_NAME = "resume_db"
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

Prepare Training Data:

Create or modify the data/train_data.csv file. This CSV file provides the data for the Machine Learning model. It should contain columns for skill_match_count, experience, and suitability_score. The quality of this data directly impacts the accuracy of the ML model.

# data/train_data.csv
skill_match_count,experience,suitability_score
5,3,75
8,5,90
2,1,40
...
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Csv
IGNORE_WHEN_COPYING_END

Train the Machine Learning Model:

python ml_model/train_model.py
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

This script trains a linear regression model using the data from train_data.csv and saves it to ml_model/model.joblib.

Run the Database Creation Script:

python models.py
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

This will create the database tables if they don't exist.

Run the Streamlit Application:

streamlit run app.py
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

Open your web browser and navigate to the address displayed in the console (usually http://localhost:8501).

Usage

Upload Resumes: Upload resume files (DOCX, PDF, TXT) using the file uploader in the application.

Upload Job Description: Upload a job description file (TXT, DOCX, PDF).

Review Ranked Resumes: The application will process the resumes, extract relevant information, and rank them based on their suitability for the job description. The ranking considers skill matching, experience, and the machine learning model's prediction.

Key Files

app.py: The main Streamlit application.

config.py: Database configuration and other settings. Important: Configure your database credentials here.

models.py: SQLAlchemy database models.

resume_parser/parser.py: Resume parsing logic.

data/train_data.csv: Training data for the machine learning model. Important: Modify this file with your own training data.

ml_model/train_model.py: ML model training script.

ml_model/model.joblib: Trained ML model (generated by train_model.py).

Important Considerations

Machine Learning Model Accuracy: The performance of the machine learning model depends on the quality and quantity of the training data. Make sure your train_data.csv file is well-populated with realistic and representative data.

Dependencies: Ensure that all required dependencies are installed correctly.

Error Handling: The application includes basic error handling, but you may need to add more robust error handling for production deployments.

Customization

Database Credentials: Customize the database credentials in config.py.

Machine Learning Model: Modify the ml_model/train_model.py script to experiment with different machine learning models or features. Remember to retrain the model after making changes.

Ranking Weights: Adjust the ranking weights in config.py to fine-tune the ranking algorithm.

# config.py
SKILL_MATCH_WEIGHT = 10
EXPERIENCE_WEIGHT = 1
ML_MODEL_WEIGHT = 5
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END
Contributing

